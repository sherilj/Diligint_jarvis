import os
from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
from tqdm import tqdm

# 1ï¸âƒ£ Load environment variables
load_dotenv()

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
INDEX_NAME = "jarvis-assistant-index"

if not PINECONE_API_KEY:
    raise ValueError("âŒ Missing Pinecone API key in .env file")
if not OPENAI_API_KEY:
    raise ValueError("âŒ Missing OpenAI API key in .env file")

# 2ï¸âƒ£ Initialize Pinecone client
pc = Pinecone(api_key=PINECONE_API_KEY)

# 3ï¸âƒ£ Create index if it doesnâ€™t exist
existing_indexes = [i["name"] for i in pc.list_indexes()]
print(f"ğŸ“œ Existing indexes: {existing_indexes}")

if INDEX_NAME not in existing_indexes:
    print("ğŸ†• Creating Pinecone index...")
    pc.create_index(
        name=INDEX_NAME,
        dimension=1536,  # Must match embedding size
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )

# 4ï¸âƒ£ Connect to index
index = pc.Index(INDEX_NAME)
print("âœ… Connected to Pinecone index:", INDEX_NAME)

# 5ï¸âƒ£ Load your documents
print("ğŸ“„ Loading documents...")
loader = DirectoryLoader("data", glob="**/*.txt")  # Change if using PDF/Docs
docs = loader.load()

# 6ï¸âƒ£ Split into chunks
print("âœ‚ï¸ Splitting into chunks...")
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
docs = splitter.split_documents(docs)

# 7ï¸âƒ£ Generate embeddings
print("ğŸ§  Generating embeddings...")
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# 8ï¸âƒ£ Upload to Pinecone
print("ğŸš€ Uploading to Pinecone...")
for doc in tqdm(docs):
    metadata = {"source": doc.metadata.get("source", "unknown")}
    vector = embeddings.embed_query(doc.page_content)
    index.upsert(vectors=[(str(hash(doc.page_content)), vector, metadata)])

print("ğŸ‰ Ingestion complete! Documents successfully embedded and uploaded.")
